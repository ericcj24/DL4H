{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Before you use this template\n",
        "\n",
        "This template is just a recommended template for project Report. It only considers the general type of research in our paper pool. Feel free to edit it to better fit your project. You will iteratively update the same notebook submission for your draft and the final submission. Please check the project rubriks to get a sense of what is expected in the template.\n",
        "\n",
        "---\n",
        "\n",
        "# FAQ and Attentions\n",
        "* Copy and move this template to your Google Drive. Name your notebook by your team ID (upper-left corner). Don't eidt this original file.\n",
        "* This template covers most questions we want to ask about your reproduction experiment. You don't need to exactly follow the template, however, you should address the questions. Please feel free to customize your report accordingly.\n",
        "* any report must have run-able codes and necessary annotations (in text and code comments).\n",
        "* The notebook is like a demo and only uses small-size data (a subset of original data or processed data), the entire runtime of the notebook including data reading, data process, model training, printing, figure plotting, etc,\n",
        "must be within 8 min, otherwise, you may get penalty on the grade.\n",
        "  * If the raw dataset is too large to be loaded  you can select a subset of data and pre-process the data, then, upload the subset or processed data to Google Drive and load them in this notebook.\n",
        "  * If the whole training is too long to run, you can only set the number of training epoch to a small number, e.g., 3, just show that the training is runable.\n",
        "  * For results model validation, you can train the model outside this notebook in advance, then, load pretrained model and use it for validation (display the figures, print the metrics).\n",
        "* The post-process is important! For post-process of the results,please use plots/figures. The code to summarize results and plot figures may be tedious, however, it won't be waste of time since these figures can be used for presentation. While plotting in code, the figures should have titles or captions if necessary (e.g., title your figure with \"Figure 1. xxxx\")\n",
        "* There is not page limit to your notebook report, you can also use separate notebooks for the report, just make sure your grader can access and run/test them.\n",
        "* If you use outside resources, please refer them (in any formats). Include the links to the resources if necessary."
      ],
      "metadata": {
        "id": "j01aH0PR4Sg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Notebook to Google Drive\n",
        "Upload the data, pretrianed model, figures, etc to your Google Drive, then mount this notebook to Google Drive. After that, you can access the resources freely.\n",
        "\n",
        "Instruction: https://colab.research.google.com/notebooks/io.ipynb\n",
        "\n",
        "Example: https://colab.research.google.com/drive/1srw_HFWQ2SMgmWIawucXfusGzrj1_U0q\n",
        "\n",
        "Video: https://www.youtube.com/watch?v=zc8g8lGcwQU"
      ],
      "metadata": {
        "id": "dlv6knX04FiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8Lov_KHFFdT",
        "outputId": "5876a928-959c-4ade-9236-847d711b7d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/DL4H/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC9b9XljE_mZ",
        "outputId": "c1e1af52-55f6-494d-8740-a8c24c7d80b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DL4H_Team_134\t\t\t\t\t\t\t\t tranferlearning1.png\n",
            "ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "Electrocardiogram (ECG) is a quick test to detect heart beat, it records electric signals of the heart. The result of the measurement help detect irregular heart beat.[9]\n",
        "\n",
        "*   ECG data is produced by various real time monitoring device types manufactured with a wide range of accuracies and noise levels, the primary issues for ECG Classification through traditional DNN methods are -\n",
        "  * The rare occurrence of anomalies in continuous ECG data leads to Class imbalance\n",
        "  * Low signal quality arising due to low sampling frequency.\n",
        "  * Human experts are required to annotate the sample to achieve acceptable accuracy, this expert interaction is an expensive activity.\n",
        "\n",
        "The third limitation is the one this paper targets to solve by applying the specific approach described below. Alternative approaches exist to handle this limitation like Active Learning and semi-supervised learning but the primary method we will be working on is Transfer learning.\n",
        "  * what did the paper propose\n",
        "  * what is the innovations of the method\n",
        "\n",
        "This paper uses Transfer Learning techniques to pretrain the large amount of publicly available raw ECG data in Icentia11K [2] (labeled and unlabeled samples are used as part of pre training tasks) and transfer the weights from the model as an input to CNN which will then use this input to finetune the model and will try to classify Atrial Fibrillation (AF, this is a severe type of heart arrhythmia) on PhysioNet/CinC 2017 input data set [3][4].\n",
        "\n",
        "The concept of Transfer Learning is applied extensively in computer vision for classification algorithms; this relies on the theory that knowledge extracted from a large dataset can be applied in a similar domain to improve the model performance for a completely different kind of classification. This paper pretrains the data for heart failure classification, using the weights as starting point, instead of random weights initialization, to obtain a more accurate AF classification on smaller target dataset in PhysioNet/CinC 2017 data set [3][4].\n",
        "\n",
        "  * how well the proposed method work (in its own metrics)\n",
        "  * what is the contribution to the reasearch regime (referring the Background above, how important the paper is to the problem).\n",
        "\n"
      ],
      "metadata": {
        "id": "MQ0sNuMePBXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code comment is used as inline annotations for your coding"
      ],
      "metadata": {
        "id": "ABD4VhFZbehA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scope of Reproducibility:\n",
        "\n",
        "List hypotheses from the paper we will test and the corresponding experiments we will run.\n",
        "\n",
        "We have constructed following hypothesis:\n",
        "\n",
        "1.   Hypothesis 1: Beat, Rhythm and Heart Rate classification pre-training methods will have better F1 score than the random weights initialization methods.\n",
        "2.   Hypothesis 2: Pre-training will improve the training times in addition to increase in performance when compared to random weights initialization.\n",
        "3.   Hypothesis 3: Pretraining allows models to be trained on less data and still achieve the same degree of performance as the same models that are not pretrained.\n",
        "4.   Hypothesis 4: Future predictions will work with acceptable accuracy when using pre-trained models on downstream datasets like PTB-XL database [5]\n",
        "\n",
        "We will device following experiments to test above hypthesis:\n",
        "\n",
        "1. In experiment 1, We will pre-train the model on Icentia dataset, then transfer the weights for downstream fine-tuning model (model 1), we will separately train a model with weight that is randomly initialiazed (model 2), we will verify our hypothesis 1 that model 1 should have better f1 score.\n",
        "\n",
        "2. During experiment 1, we will record the epoch used in training both models, and test hypothesis 2 by observing which model performs better with same training epoch.\n",
        "\n",
        "3. During experiment 1, we will record the volume of data used in training both models, and test hypothesis 3, by observing the performance difference of the models when data volume used in testing are the same.\n",
        "\n",
        "4. We will proceed to use PTB-XL database to fine-tune the model, and record downstream model (model 3) performance on hold-out dataset.\n",
        "\n",
        "\n",
        "You can insert images in this notebook text, [see this link](https://stackoverflow.com/questions/50670920/how-to-insert-an-inline-image-in-google-colaboratory-from-google-drive) and example below:\n",
        "\n",
        "![sample_image.png](https://drive.google.com/uc?export=view&id=1g2efvsRJDxTxKz-OY3loMhihrEUdBxbc)\n"
      ],
      "metadata": {
        "id": "uygL9tTPSVHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "You can also use code to display images, see the code below.\n",
        "\n",
        "The images must be saved in Google Drive first.\n"
      ],
      "metadata": {
        "id": "LM4WUjz64C3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "'''\n",
        "if you want to use an image outside this notebook for explanaition,\n",
        "you can upload it to your google drive and show it with OpenCV or matplotlib\n",
        "'''\n",
        "# mount this notebook to your google drive\n",
        "#drive.mount('/content/gdrive')\n",
        "\n",
        "# define dirs to workspace and data\n",
        "img_dir = '/content/gdrive/MyDrive/DL4H/transferlearning1.png'\n",
        "\n",
        "\n",
        "cv2_imshow(img_dir)\n",
        "\n"
      ],
      "metadata": {
        "id": "rRksCB1vbYwJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "3e16f7eb-7f63-4b51-c315-9a599dfa6d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'clip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-665ffed76770>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/patches/__init__.py\u001b[0m in \u001b[0;36mcv2_imshow\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0man\u001b[0m \u001b[0mNxM\u001b[0m \u001b[0mBGRA\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \"\"\"\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0;31m# cv2 stores colors as BGR; convert to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'clip'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology\n",
        "\n",
        "This methodology is the core of your project. It consists of run-able codes with necessary annotations to show the expeiment you executed for testing the hypotheses.\n",
        "\n",
        "The methodology at least contains two subsections **data** and **model** in your experiment."
      ],
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import  packages you need\n",
        "import numpy as np\n",
        "from google.colab import drive\n"
      ],
      "metadata": {
        "id": "yu61Jp1xrnKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Data\n",
        "Data includes raw data (MIMIC III tables), descriptive statistics (our homework questions), and data processing (feature engineering).\n",
        "  * Source of the data: where the data is collected from; if data is synthetic or self-generated, explain how. If possible, please provide a link to the raw datasets.\n",
        "  * Statistics: include basic descriptive statistics of the dataset like size, cross validation split, label distribution, etc.\n",
        "  * Data process: how do you munipulate the data, e.g., change the class labels, split the dataset to train/valid/test, refining the dataset.\n",
        "  * Illustration: printing results, plotting figures for illustration.\n",
        "  * You can upload your raw dataset to Google Drive and mount this Colab to the same directory. If your raw dataset is too large, you can upload the processed dataset and have a code to load the processed dataset."
      ],
      "metadata": {
        "id": "2NbPHUTMbkD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XzVUQS0CHry0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZScZNbROw-N"
      },
      "outputs": [],
      "source": [
        "# dir and function to load raw data\n",
        "raw_data_dir = '/content/gdrive/My Drive/Colab Notebooks/<path-to-raw-data>'\n",
        "\n",
        "def load_raw_data(raw_data_dir):\n",
        "  # implement this function to load raw data to dataframe/numpy array/tensor\n",
        "  return None\n",
        "\n",
        "raw_data = load_raw_data(raw_data_dir)\n",
        "\n",
        "# calculate statistics\n",
        "def calculate_stats(raw_data):\n",
        "  # implement this function to calculate the statistics\n",
        "  # it is encouraged to print out the results\n",
        "  return None\n",
        "\n",
        "# process raw data\n",
        "def process_data(raw_data):\n",
        "    # implement this function to process the data as you need\n",
        "  return None\n",
        "\n",
        "processed_data = process_data(raw_data)\n",
        "\n",
        "''' you can load the processed data directly\n",
        "processed_data_dir = '/content/gdrive/My Drive/Colab Notebooks/<path-to-raw-data>'\n",
        "def load_processed_data(raw_data_dir):\n",
        "  pass\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##   Model\n",
        "The model includes the model definitation which usually is a class, model training, and other necessary parts.\n",
        "  * Model architecture: layer number/size/type, activation function, etc\n",
        "  * Training objectives: loss function, optimizer, weight of each loss term, etc\n",
        "  * Others: whether the model is pretrained, Monte Carlo simulation for uncertainty analysis, etc\n",
        "  * The code of model should have classes of the model, functions of model training, model validation, etc.\n",
        "  * If your model training is done outside of this notebook, please upload the trained model here and develop a function to load and test it."
      ],
      "metadata": {
        "id": "3muyDPFPbozY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class my_model():\n",
        "  # use this class to define your model\n",
        "  pass\n",
        "\n",
        "model = my_model()\n",
        "loss_func = None\n",
        "optimizer = None\n",
        "\n",
        "def train_model_one_iter(model, loss_func, optimizer):\n",
        "  pass\n",
        "\n",
        "num_epoch = 10\n",
        "# model training loop: it is better to print the training/validation losses during the training\n",
        "for i in range(num_epoch):\n",
        "  train_model_one_iter(model, loss_func, optimizer)\n",
        "  train_loss, valid_loss = None, None\n",
        "  print(\"Train Loss: %.2f, Validation Loss: %.2f\" % (train_loss, valid_loss))\n"
      ],
      "metadata": {
        "id": "gBdVZoTvsSFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "In this section, you should finish training your model training or loading your trained model. That is a great experiment! You should share the results with others with necessary metrics and figures.\n",
        "\n",
        "Please test and report results for all experiments that you run with:\n",
        "\n",
        "*   specific numbers (accuracy, AUC, RMSE, etc)\n",
        "*   figures (loss shrinkage, outputs from GAN, annotation or label of sample pictures, etc)\n"
      ],
      "metadata": {
        "id": "gX6bCcZNuxmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics to evaluate my model\n",
        "\n",
        "# plot figures to better show the results\n",
        "\n",
        "# it is better to save the numbers and figures for your presentation."
      ],
      "metadata": {
        "id": "LjW9bCkouv8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model comparison"
      ],
      "metadata": {
        "id": "8EAWAy_LwHlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compare you model with others\n",
        "# you don't need to re-run all other experiments, instead, you can directly refer the metrics/numbers in the paper"
      ],
      "metadata": {
        "id": "uOdhGrbwwG71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion\n",
        "\n",
        "In this section,you should discuss your work and make future plan. The discussion should address the following questions:\n",
        "  * Make assessment that the paper is reproducible or not.\n",
        "  * Explain why it is not reproducible if your results are kind negative.\n",
        "  * Describe “What was easy” and “What was difficult” during the reproduction.\n",
        "  * Make suggestions to the author or other reproducers on how to improve the reproducibility.\n",
        "  * What will you do in next phase.\n",
        "\n"
      ],
      "metadata": {
        "id": "qH75TNU71eRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# no code is required for this section\n",
        "'''\n",
        "if you want to use an image outside this notebook for explanaition,\n",
        "you can read and plot it here like the Scope of Reproducibility\n",
        "'''"
      ],
      "metadata": {
        "id": "E2VDXo5F4Frm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "1. Weimann, K., Conrad, T.O.F. Transfer learning for ECG classification. Sci Rep 11, 5251 (2021). https://doi.org/10.1038/s41598-021-84374-8 https://github.com/kweimann/ecg-transfer-learning/tree/master\n",
        "\n",
        "2. Tan, S. et al. Icentia11K: An Unsupervised Representation Learning Dataset for Arrhythmia Subtype Discovery (2019). arXiv:arXiv:1910.09570\n",
        "\n",
        "3. Clifford, G. D. et al. AF Classification from a short single lead ECG recording: the PhysioNet/computing in cardiology challenge 2017. Comput. Cardiol. (2017).In 2017 Computing in Cardiology (CinC) 2017 Sep 24 (pp. 1-4). IEEE. https://doi.org/10.22489/CinC.2017.065-469\n",
        "\n",
        "4. Goldberger, A. L. et al. PhysioBank, PhysioToolkit, and PhysioNet: components of a new research resource for complex physiologic signals. Circulation 101, e215–e220. https://doi.org/10.1161/01.CIR.101.23.e215 (2000).\n",
        "\n",
        "5. Strodthoff, N., Wagner, P., Schaeffter, T., & Samek, W. Deep Learning for ECG Analysis: Benchmarks and Insights from PTB-XL (2020). arXiv:2004.13701.\n",
        "\n",
        "6. van den Oord, A., Li, Y., & Vinyals, O. Representation Learning with Contrastive Predictive Coding (2019). arXiv:1807.03748.\n",
        "\n",
        "7. He, K., Zhang, X., Ren, S., & Sun, J. Deep Residual Learning for Image Recognition (2015). arXiv:1512.03385.\n",
        "\n",
        "8. Liu, F. et al. An open access database for evaluating the algorithms of electrocardiogram rhythm and morphology abnormality detection. J. Med. Imaging Health Inf. 8, 1368–1373. https://doi.org/10.1166/jmihi.2018.2442 (2018).\n",
        "\n",
        "9. https://www.mayoclinic.org/tests-procedures/ekg/about/pac-20384983\n"
      ],
      "metadata": {
        "id": "SHMI2chl9omn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feel free to add new sections"
      ],
      "metadata": {
        "id": "xmVuzQ724HbO"
      }
    }
  ]
}